{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Demo\n",
    "\n",
    "This notebook demonstrates the use of the Confidential Training tool. It requires the [avato Training API](https://github.com/decentriq/avato-python-client-training) and its dependencies to be installed.  \n",
    "\n",
    "Note that in a realistic, non-demo use of the Confidential Training tool, one admin user and multiple participant users would upload data from different computers. In this workbook, for simplicity, the workflows of the admin user and the two participant users are all shown together.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from avato import Client\n",
    "from avato import Secret\n",
    "from avato_training import Training_Instance, Configuration\n",
    "\n",
    "admin_username = \"***REMOVED***\"\n",
    "admin_***REMOVED*** = \"***REMOVED***\"\n",
    "\n",
    "participant1_username = \"***REMOVED***\"\n",
    "participant1_***REMOVED*** = \"***REMOVED***\"\n",
    "\n",
    "participant2_username = \"***REMOVED***\"\n",
    "participant2_***REMOVED*** = \"***REMOVED***\"\n",
    "\n",
    "# This is the hash of the code\n",
    "expected_measurement = \"4ff505f350698c78e8b3b49b8e479146ce3896a06cd9e5109dfec8f393f14025\"\n",
    "\n",
    "backend_host = \"localhost\" \n",
    "backend_port = 3000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADMIN USER - Set Up Instance\n",
    "#### Create new instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance ID: 780827e6-9e95-43b3-8188-7e8c25dca62c\n"
     ]
    }
   ],
   "source": [
    "# Create client.\n",
    "admin_client = Client(\n",
    "    username=admin_username,\n",
    "    ***REMOVED***=admin_***REMOVED***,\n",
    "    instance_types=[Training_Instance],\n",
    "    backend_host=backend_host,\n",
    "    backend_port=backend_port\n",
    ")\n",
    "\n",
    "# Spin up an instance. Set who can participate in the instance.\n",
    "admin_instance = admin_client.create_instance(\n",
    "    \"Training\", \n",
    "    Training_Instance.type, \n",
    "    [participant1_username, participant2_username]\n",
    ")\n",
    "print(\"Instance ID: {}\".format(admin_instance.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check security guarantees\n",
    "Validating the so-called fatquote. This step is crucial for all security guarantees.\n",
    "This step gets and validates the cryptographic proof from the enclave:\n",
    "\n",
    "* i)   It proves it is a valid SGX enclave (by checking a certificate).\n",
    "* ii)  It compares the hash of the enclave code provided by the user to\n",
    "     an expected value (to verify what code is running in the enclave).\n",
    "* iii) As part of the proof also a public key is transmitted that allows\n",
    "     establishing a secure connection into the enclave (as the private\n",
    "     key is only known to the enclave).\n",
    "     \n",
    "As we are using a non-production environment, we whitelist the debug and out_of_data flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_instance.validate_fatquote(\n",
    "    expected_measurement=expected_measurement,\n",
    "    accept_debug=True,\n",
    "    accept_group_out_of_date=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quote is part of the fatquote and provides a detailed fingerprint of the program and state of the remote machine. For example:\n",
    "* using `flags` we can detect if the CPU is running in un-trusted debug mode\n",
    "* using `*_snv` we can verify if all security patches have been deployed to the infrastructure\n",
    "* using `mrenclave` we can attest to the exact program being executed on the remote machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to inspect \n",
    "# print(admin_instance.quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration\n",
    "configuration = Configuration(\n",
    "    categories_columns=[\"x_1\", \"x_2\", \"x_3\", \"x_4\"],\n",
    "    value_column=\"y\",\n",
    "    ***REMOVED***=admin_***REMOVED*** # the ***REMOVED*** to execute\n",
    ")\n",
    "\n",
    "# Create and set public-private keypair for secure communication.\n",
    "admin_secret = Secret()\n",
    "admin_instance.set_secret(admin_secret)\n",
    "\n",
    "# Upload\n",
    "admin_instance.upload_configuration(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTICIPANT USERS - Submit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function submits for a given participant a data file to the instance.\n",
    "def participant_submit_data(participant_username, participant_***REMOVED***, instance_id, data_file):\n",
    "\n",
    "    # Create client\n",
    "    participant_client = Client(\n",
    "        username=participant_username,\n",
    "        ***REMOVED***=participant_***REMOVED***,\n",
    "        instance_types=[Training_Instance],\n",
    "        backend_host=backend_host,\n",
    "        backend_port=backend_port\n",
    "    )\n",
    "\n",
    "    # Connect to instance (using ID from the admin user)\n",
    "    participant_instance = participant_client.get_instance(instance_id)\n",
    "\n",
    "    # Check security guarantees.\n",
    "    participant_instance.validate_fatquote(\n",
    "        expected_measurement=expected_measurement,\n",
    "        accept_debug=True,\n",
    "        accept_group_out_of_date=True\n",
    "    )\n",
    "\n",
    "    # Create and set public-private keypair for secure communication.\n",
    "    participant_secret = Secret()\n",
    "    participant_instance.set_secret(participant_secret)\n",
    "\n",
    "    # Get data format from the enclave\n",
    "    data_format = participant_instance.get_data_format()\n",
    "    print(\"Data format:\\n{}\".format(data_format))\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    print(\"Loaded data:\\n\")\n",
    "    print(df)\n",
    "\n",
    "    # Submit data\n",
    "    (ingested_rows, failed_rows) = participant_instance.submit_data(df)\n",
    "    print(\"Number of successfully ingested rows: {}, number of failed rows: {}\".format(ingested_rows, failed_rows))\n",
    "    \n",
    "    return participant_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARTICIPANT 1 - Submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data format:\n",
      "categoriesColumns: \"x_1\"\n",
      "categoriesColumns: \"x_2\"\n",
      "categoriesColumns: \"x_3\"\n",
      "categoriesColumns: \"x_4\"\n",
      "valueColumn: \"y\"\n",
      "\n",
      "Loaded data:\n",
      "\n",
      "    x_1  x_2  x_3  x_4  y\n",
      "0   5.1  3.5  1.4  0.2  0\n",
      "1   4.9  3.0  1.4  0.2  0\n",
      "2   4.7  3.2  1.3  0.2  0\n",
      "3   4.6  3.1  1.5  0.2  0\n",
      "4   5.0  3.6  1.4  0.2  0\n",
      "..  ...  ...  ...  ... ..\n",
      "70  5.9  3.2  4.8  1.8  1\n",
      "71  6.1  2.8  4.0  1.3  1\n",
      "72  6.3  2.5  4.9  1.5  1\n",
      "73  6.1  2.8  4.7  1.2  1\n",
      "74  6.4  2.9  4.3  1.3  1\n",
      "\n",
      "[75 rows x 5 columns]\n",
      "Number of successfully ingested rows: 75, number of failed rows: []\n"
     ]
    }
   ],
   "source": [
    "participant1_instance = participant_submit_data(\n",
    "    participant1_username, \n",
    "    participant1_***REMOVED***, \n",
    "    admin_instance.id, \n",
    "    \"./test-data/participant1_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARTICIPANT 2 - Submit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data format:\n",
      "categoriesColumns: \"x_1\"\n",
      "categoriesColumns: \"x_2\"\n",
      "categoriesColumns: \"x_3\"\n",
      "categoriesColumns: \"x_4\"\n",
      "valueColumn: \"y\"\n",
      "\n",
      "Loaded data:\n",
      "\n",
      "    x_1  x_2  x_3  x_4  y\n",
      "0   6.6  3.0  4.4  1.4  1\n",
      "1   6.8  2.8  4.8  1.4  1\n",
      "2   6.7  3.0  5.0  1.7  1\n",
      "3   6.0  2.9  4.5  1.5  1\n",
      "4   5.7  2.6  3.5  1.0  1\n",
      "..  ...  ...  ...  ... ..\n",
      "70  6.7  3.0  5.2  2.3  2\n",
      "71  6.3  2.5  5.0  1.9  2\n",
      "72  6.5  3.0  5.2  2.0  2\n",
      "73  6.2  3.4  5.4  2.3  2\n",
      "74  5.9  3.0  5.1  1.8  2\n",
      "\n",
      "[75 rows x 5 columns]\n",
      "Number of successfully ingested rows: 75, number of failed rows: []\n"
     ]
    }
   ],
   "source": [
    "participant2_instance = participant_submit_data(\n",
    "    participant2_username, \n",
    "    participant2_***REMOVED***, \n",
    "    admin_instance.id, \n",
    "    \"./test-data/participant2_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADMIN USER - Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJPxVc3d4wnr"
   },
   "outputs": [],
   "source": [
    "admin_instance.start_execution(admin_***REMOVED***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTICIPANT USERS - Get Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARTICIPANT 1 - Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = participant1_instance.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARTICIPANT 2 - Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = participant2_instance.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADMIN USER - Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7S_abhv4wqD"
   },
   "outputs": [],
   "source": [
    "admin_instance.shutdown()\n",
    "admin_instance.delete()\n",
    "assert admin_instance.id not in admin_client.get_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "0.0 0.0 0\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 2\n",
      "1.0 1.0 2\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "1.0 1.0 1\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "2.0 2.0 2\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_data():\n",
    "    Xy = np.array(\n",
    "        pd.concat([\n",
    "            pd.read_csv(\"./test-data/participant1_data.csv\"),\n",
    "            pd.read_csv(\"./test-data/participant2_data.csv\")\n",
    "        ])\n",
    "    );\n",
    "    X = Xy[:,0:4]\n",
    "    y = Xy[:,4]\n",
    "    return X, y\n",
    "\n",
    "X, y = get_data()\n",
    "y_hat = classifier1.predict(X)\n",
    "\n",
    "assert len(y) == len(y_hat)\n",
    "n = len(y)\n",
    "n_eq = 0\n",
    "for yi, yi_hat in zip(y, y_hat):\n",
    "    print(yi, float(yi), yi_hat)\n",
    "    if float(yi) == float(yi_hat):\n",
    "        n_eq = n_eq + 1\n",
    "print(float(n_eq)/n)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as npd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(CustomOvrLinearRegressionClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "class TemplateClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, demo_param='demo'):\n",
    "        self.demo_param = demo_param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        closest = np.argmin(euclidean_distances(X, self.X_), axis=1)\n",
    "        return self.y_[closest]\n",
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(TemplateClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Benchmarking_Demo_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
