{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidential ML Training Demo (Analyst)\n",
    "\n",
    "This notebook is the Analyst part of the *Confidential ML Training Demo* showing how a simple logistic regression classifier can be trained while keeping the training data provably confidential. The demo requires the [Training Client API](https://github.com/decentriq/avato-python-client-training) and its dependencies to be installed.  \n",
    "\n",
    "Note that while we demo the training of a logistic regression enclave, it can be used to train a variety of other classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Import dependencies and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from avato import Client\n",
    "from avato import Secret\n",
    "from avato_training import Training_Instance, Configuration\n",
    "import numpy as np\n",
    "import example\n",
    "\n",
    "analyst_username, analyst_***REMOVED*** = example.analyst_credentials\n",
    "\n",
    "# The analyst needs these to control who can upload data\n",
    "dataowner1_username = os.getenv('DATAOWNER1_ID')\n",
    "dataowner2_username = os.getenv('DATAOWNER2_ID')\n",
    "\n",
    "# This is the hash of the code\n",
    "expected_measurement = \"4ff505f350698c78e8b3b49b8e479146ce3896a06cd9e5109dfec8f393f14025\"\n",
    "\n",
    "# How the analyst expects the data to be formatted\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "label_column = \"quality\"\n",
    "\n",
    "# This points to the confidential computing system\n",
    "backend_host = \"localhost\" \n",
    "backend_port = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Set up instance\n",
    "### Create new instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create client.\n",
    "analyst_client = Client(\n",
    "    username=analyst_username,\n",
    "    ***REMOVED***=analyst_***REMOVED***,\n",
    "    instance_types=[Training_Instance],\n",
    "    backend_host=backend_host,\n",
    "    backend_port=backend_port\n",
    ")\n",
    "\n",
    "# Spin up an instance. Set who can participate in the instance.\n",
    "analyst_instance = analyst_client.create_instance(\n",
    "    \"Training\", \n",
    "    Training_Instance.type, \n",
    "    [dataowner1_username, dataowner2_username]\n",
    ")\n",
    "print(\"Instance ID: {}\".format(analyst_instance.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify security\n",
    "Validating the so-called fatquote. This is crucial for all security guarantees.\n",
    "This step gets and validates the cryptographic proof from the enclave:\n",
    "\n",
    "* i)   It proves it is a valid SGX enclave (by checking a certificate).\n",
    "* ii)  It compares the hash of the enclave code provided by the user to\n",
    "     an expected value (to verify what code is running in the enclave).\n",
    "* iii) As part of the proof also a public key is transmitted that allows\n",
    "     establishing a secure connection into the enclave (as the private\n",
    "     key is only known to the enclave).\n",
    "     \n",
    "As we are using a non-production environment, we whitelist the debug and out_of_data flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyst_instance.validate_fatquote(\n",
    "    expected_measurement=expected_measurement,\n",
    "    accept_debug=True,\n",
    "    accept_group_out_of_date=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration\n",
    "configuration = Configuration(\n",
    "    feature_columns=feature_columns,\n",
    "    label_column=label_column,\n",
    "    ***REMOVED***=analyst_***REMOVED*** # the ***REMOVED*** to execute\n",
    ")\n",
    "\n",
    "# Create and set public-private keypair for secure communication.\n",
    "analyst_secret = Secret()\n",
    "analyst_instance.set_secret(analyst_secret)\n",
    "\n",
    "# Upload\n",
    "analyst_instance.upload_configuration(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train model (after data has been uploaded by the Dataowners)\n",
    "### Train with first set of hyperparameters\n",
    "This returns the trained classifier and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJPxVc3d4wnr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_splits\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"l2_penalty\": 0.0,\n",
    "    \"l1_penalty\": 0.0,\n",
    "}\n",
    "\n",
    "analyst_instance.start_execution(analyst_***REMOVED***, hyperparameters)\n",
    "\n",
    "classifier, metadata = analyst_instance.get_results(analyst_***REMOVED***)\n",
    "print(\"metadata: {}\".format(json.dumps(metadata, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with second set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 1.0,\n",
    "    \"num_splits\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"l2_penalty\": 0.0,\n",
    "    \"l1_penalty\": 0.0,\n",
    "}\n",
    "\n",
    "analyst_instance.start_execution(analyst_***REMOVED***, hyperparameters)\n",
    "\n",
    "classifier, metadata = analyst_instance.get_results(analyst_***REMOVED***)\n",
    "print(\"metadata: {}\".format(json.dumps(metadata, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Use the classifier\n",
    "### Use classifier, compute accuracy on full dataset, compare with metadata results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = example.load_data()\n",
    "accuracy = example.compute_accuracy(classifier, X, y)\n",
    "\n",
    "print(\"Some predictions of the classifier: {}\".format(classifier.predict(X[0:2, :])))\n",
    "print(\"Accuracy of the enclave classifier on the full dataset (as returned through the metadata object): {}\".format(metadata[\"Fullset Accuracy\"]))\n",
    "print(\"Accuracy of the local classifier on the full dataset: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7S_abhv4wqD"
   },
   "outputs": [],
   "source": [
    "analyst_instance.shutdown()\n",
    "analyst_instance.delete()\n",
    "assert analyst_instance.id not in analyst_client.get_instances()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Benchmarking_Demo_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
