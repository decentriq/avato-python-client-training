{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Demo\n",
    "\n",
    "This notebook demonstrates the use of the Confidential Training tool. It requires the [avato Training API](https://github.com/decentriq/avato-python-client-training) and its dependencies to be installed.  \n",
    "\n",
    "Note that in a realistic, non-demo use of the Confidential Training tool, one analyst user and multiple dataowner users would upload data from different computers. In this workbook, for simplicity, the workflows of the analyst user and the two dataowner users are all shown together.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from avato import Client\n",
    "from avato import Secret\n",
    "from avato_training import Training_Instance, Configuration\n",
    "import numpy as np\n",
    "\n",
    "analyst_username = os.getenv('ANALYST_ID')\n",
    "analyst_password = os.getenv('ANALYST_PASSWORD')\n",
    "\n",
    "dataowner1_username = os.getenv('DATAOWNER1_ID')\n",
    "dataowner1_password = os.getenv('DATAOWNER1_PASSWORD')\n",
    "\n",
    "dataowner2_username = os.getenv('DATAOWNER2_ID')\n",
    "dataowner2_password = os.getenv('DATAOWNER2_PASSWORD')\n",
    "\n",
    "# This is the hash of the code\n",
    "expected_measurement = \"8e6c77bd904826526918a7e8fd4ccdc35cb8f8b5e0241fc78749e80dedf00cdf\"\n",
    "\n",
    "# How the analyst expects the data to be formatted\n",
    "feature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "label_column = \"quality\"\n",
    "\n",
    "# The datafiles uploaded by the \n",
    "dataowner1_file = \"test-data/wine-dataowner1.csv\"\n",
    "dataowner2_file = \"test-data/wine-dataowner2.csv\"\n",
    "\n",
    "backend_host = \"avato.uksouth.cloudapp.azure.com\" \n",
    "backend_port = 15005 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYST USER\n",
    "#### Create new instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client.\n",
    "analyst_client = Client(\n",
    "    username=analyst_username,\n",
    "    password=analyst_password,\n",
    "    instance_types=[Training_Instance],\n",
    "    backend_host=backend_host,\n",
    "    backend_port=backend_port\n",
    ")\n",
    "\n",
    "# Spin up an instance. Set who can participate in the instance.\n",
    "analyst_instance = analyst_client.create_instance(\n",
    "    \"Training\", \n",
    "    Training_Instance.type, \n",
    "    [dataowner1_username, dataowner2_username]\n",
    ")\n",
    "print(\"Instance ID: {}\".format(analyst_instance.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check security guarantees\n",
    "Validating the so-called fatquote. This step is crucial for all security guarantees.\n",
    "This step gets and validates the cryptographic proof from the enclave:\n",
    "\n",
    "* i)   It proves it is a valid SGX enclave (by checking a certificate).\n",
    "* ii)  It compares the hash of the enclave code provided by the user to\n",
    "     an expected value (to verify what code is running in the enclave).\n",
    "* iii) As part of the proof also a public key is transmitted that allows\n",
    "     establishing a secure connection into the enclave (as the private\n",
    "     key is only known to the enclave).\n",
    "     \n",
    "As we are using a non-production environment, we whitelist the debug and out_of_data flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instance.validate_fatquote(\n",
    "    expected_measurement=expected_measurement,\n",
    "    accept_debug=True,\n",
    "    accept_group_out_of_date=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quote is part of the fatquote and provides a detailed fingerprint of the program and state of the remote machine. For example:\n",
    "* using `flags` we can detect if the CPU is running in un-trusted debug mode\n",
    "* using `*_snv` we can verify if all security patches have been deployed to the infrastructure\n",
    "* using `mrenclave` we can attest to the exact program being executed on the remote machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to inspect \n",
    "# print(analyst_instance.quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration\n",
    "configuration = Configuration(\n",
    "    feature_columns=feature_columns,\n",
    "    label_column=label_column,\n",
    "    password=analyst_password # the password to execute\n",
    ")\n",
    "\n",
    "# Create and set public-private keypair for secure communication.\n",
    "analyst_secret = Secret()\n",
    "analyst_instance.set_secret(analyst_secret)\n",
    "\n",
    "# Upload\n",
    "analyst_instance.upload_configuration(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAOWNERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function submits for a given dataowner a data file to the instance.\n",
    "def dataowner_submit_data(dataowner_username, dataowner_password, instance_id, data_file):\n",
    "\n",
    "    # Create client\n",
    "    dataowner_client = Client(\n",
    "        username=dataowner_username,\n",
    "        password=dataowner_password,\n",
    "        instance_types=[Training_Instance],\n",
    "        backend_host=backend_host,\n",
    "        backend_port=backend_port\n",
    "    )\n",
    "\n",
    "    # Connect to instance (using ID from the analyst user)\n",
    "    dataowner_instance = dataowner_client.get_instance(instance_id)\n",
    "\n",
    "    # Check security guarantees.\n",
    "    dataowner_instance.validate_fatquote(\n",
    "        expected_measurement=expected_measurement,\n",
    "        accept_debug=True,\n",
    "        accept_group_out_of_date=True\n",
    "    )\n",
    "\n",
    "    # Create and set public-private keypair for secure communication.\n",
    "    dataowner_secret = Secret()\n",
    "    dataowner_instance.set_secret(dataowner_secret)\n",
    "\n",
    "    # Get data format from the enclave\n",
    "    data_format = dataowner_instance.get_data_format()\n",
    "    print(\"Data format:\\n{}\".format(data_format))\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    print(\"Loaded data:\\n\")\n",
    "    print(df)\n",
    "\n",
    "    # Submit data\n",
    "    (ingested_rows, failed_rows) = dataowner_instance.submit_data(df)\n",
    "    print(\"Number of successfully ingested rows: {}, number of failed rows: {}\".format(ingested_rows, failed_rows))\n",
    "    \n",
    "    return dataowner_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataowner 1 - Submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataowner1_instance = dataowner_submit_data(\n",
    "    dataowner1_username, \n",
    "    dataowner1_password, \n",
    "    analyst_instance.id, \n",
    "    data_file=dataowner1_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataowner 2 - Submit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataowner2_instance = dataowner_submit_data(\n",
    "    dataowner2_username, \n",
    "    dataowner2_password, \n",
    "    analyst_instance.id, \n",
    "    dataowner2_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYST\n",
    "#### Train with first set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJPxVc3d4wnr"
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_splits\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"l2_penalty\": 0.0,\n",
    "    \"l1_penalty\": 0.0,\n",
    "}\n",
    "\n",
    "analyst_instance.start_execution(analyst_password, hyperparameters)\n",
    "\n",
    "classifier, metadata = analyst_instance.get_results(analyst_password)\n",
    "print(\"metadata: {}\".format(json.dumps(metadata, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with second set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 1.0,\n",
    "    \"num_splits\": 10,\n",
    "    \"num_epochs\": 5,\n",
    "    \"l2_penalty\": 0.0,\n",
    "    \"l1_penalty\": 0.0,\n",
    "}\n",
    "\n",
    "analyst_instance.start_execution(analyst_password, hyperparameters)\n",
    "\n",
    "classifier, metadata = analyst_instance.get_results(analyst_password)\n",
    "print(\"metadata: {}\".format(json.dumps(metadata, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use classifier, compute accuracy on full dataset, compare with metadata results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    Xy = np.array(\n",
    "        pd.concat([\n",
    "            pd.read_csv(dataowner1_file),\n",
    "            pd.read_csv(dataowner2_file)\n",
    "        ])\n",
    "    );\n",
    "    X = Xy[:,0:-1]\n",
    "    y = Xy[:,-1]\n",
    "    return X, y\n",
    "\n",
    "def compute_accuracy(classifier, X, y):\n",
    "\n",
    "    y_hat = classifier.predict(X)\n",
    "    assert len(y) == len(y_hat)\n",
    "    n = len(y)\n",
    "    n_eq = 0\n",
    "    for yi, yi_hat in zip(y, y_hat):\n",
    "        if float(yi) == float(yi_hat):\n",
    "            n_eq = n_eq + 1\n",
    "    accuracy = float(n_eq)/n\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "X, y = load_data()\n",
    "accuracy = compute_accuracy(classifier, X, y)\n",
    "\n",
    "print(\"Some predictions of the classifier: {}\".format(classifier.predict(X[0:2, :])))\n",
    "print(\"Accuracy of the enclave classifier on the full dataset (as returned through the metadata object): {}\".format(metadata[\"Fullset Accuracy\"]))\n",
    "print(\"Accuracy of the local classifier on the full dataset: {}\".format(accuracy))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYST USER - Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7S_abhv4wqD"
   },
   "outputs": [],
   "source": [
    "analyst_instance.shutdown()\n",
    "analyst_instance.delete()\n",
    "assert analyst_instance.id not in analyst_client.get_instances()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Benchmarking_Demo_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
